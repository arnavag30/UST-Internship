import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow.keras as keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNet
dataset_dir = r"C:\Users\arnav\Desktop\Me\UST Global\Dataset\DRIVE"
image_size = (224, 224)
batch_size = 32
data_generator = ImageDataGenerator(
 rescale=1.0 / 255.0,
 rotation_range=20,
 width_shift_range=0.1,
 height_shift_range=0.1,
 shear_range=0.1,
 zoom_range=0.1,
 horizontal_flip=True,
 validation_split=0.2
)
train_generator = data_generator.flow_from_directory(
 dataset_dir,
 target_size=image_size,
 batch_size=batch_size,
 class_mode='categorical',
 subset='training'
)
validation_generator = data_generator.flow_from_directory(
 dataset_dir,
 target_size=image_size,
 batch_size=batch_size,
 class_mode='categorical',
 subset='validation'
)
class_labels = {
 0: 'no dr',
 1: 'dr'
}
plt.figure(figsize=(16, 16))
j = 1
for i in np.random.randint(0, len(train_generator), 15):
 plt.subplot(5, 5, j)
 j += 1
 plt.imshow(train_generator[i][0][0], cmap="Greys")
 plt.axis('off')
 label = np.argmax(train_generator[i][1][0])
 plt.title('{} / {}'.format(class_labels[label], label))
plt.show()
base_model = MobileNet(include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False
model = keras.models.Sequential([
 base_model,
 keras.layers.GlobalAveragePooling2D(),
 keras.layers.Dense(256, activation='relu'),
 keras.layers.Dense(2, activation='softmax')
])
model.summary()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(
 train_generator,
 steps_per_epoch=train_generator.samples // batch_size,
 epochs=20,
 validation_data=validation_generator,
 validation_steps=validation_generator.samples // batch_size
)
test_dir = r"C:\Users\arnav\Desktop\Me\UST Global\Dataset\DRIVE\test"
test_generator = data_generator.flow_from_directory(
 test_dir,
 target_size=image_size,
 batch_size=batch_size,
 class_mode='categorical',
 shuffle=False
)
test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)
predictions = model.predict(test_generator)
predicted_labels = np.argmax(predictions, axis=1)
true_labels = test_generator.classes
print('Test loss:', test_loss)
print('Test accuracy:', test_accuracy)
from sklearn.metrics import classification_report
classification_report = classification_report(true_labels, predicted_labels, zero_divisio
print('Classification Report:\n', classification_report)
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(true_labels, predicted_labels)
tn, fp, fn, tp = cm[0, 0], cm[0, 1], cm[1, 0], cm[1, 1]
if (tp + fn) != 0:
 sensitivity = tp / (tp + fn)
else:
 sensitivity = 0.0
specificity = tn / (tn + fp)
print("Specificity:", specificity)
print(cm)
plt.figure(figsize=(16, 16))
j = 1
for batch in train_generator:
 images, labels = batch
 for i in range(len(images)):
 plt.subplot(5, 5, j)
 j += 1
 img = images[i]
 img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
 plt.imshow(img)
 plt.axis('off')
 label = np.argmax(labels[i])
 plt.title('{} / {}'.format(class_labels[label], label))

 if j > 25:
 break
 if j > 25:
 break
plt.show()
